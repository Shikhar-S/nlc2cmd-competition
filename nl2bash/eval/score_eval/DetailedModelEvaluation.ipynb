{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Model Evaluation\n",
    "\n",
    "I tried to make a framework for in-depth evaluation of model predictions. I probably made some mistakes, tell me if you see any!\n",
    "\n",
    "This is mostly just for showcasing/development; what is here is encased in functions in `metric_utils.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from nl2bash import bashlint\n",
    "import pandas\n",
    "import numpy as np\n",
    "import metric_utils\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading csv file\n",
    "result_path = '../../model/seq2seq/bash-T-4-birnn-gru-standard-attention-0.6-0.6-0.0-copy-1.0-128-200-1-0.0001-1e-08-0.6-0.6-0.6-0.6/predictions.beam_search.100.dev.latest.csv'\n",
    "result_df = pandas.read_csv(result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>description</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>prediction</th>\n",
       "      <th>correct template</th>\n",
       "      <th>correct command</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'0</td>\n",
       "      <td>Adds execution permissions on a script ./etc/b...</td>\n",
       "      <td>chmod +x $(brew --prefix)/etc/bash_completion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>'</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>find __SP__UNK -type d -exec chmod +x {} \\\\;</td>\n",
       "      <td>'</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>find __SP__UNK -type d -exec chmod __SP__UNK {...</td>\n",
       "      <td>'</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>find __SP__UNK -type d -print0 | xargs -0 -I {...</td>\n",
       "      <td>'</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>find __SP__UNK -type f -exec chmod +x {} \\\\;</td>\n",
       "      <td>'</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b'1</td>\n",
       "      <td>Add prefix like number and \"^M${LOGFILE}&gt; \" to...</td>\n",
       "      <td>nl -s\"^M${LOGFILE}&gt;  \"</td>\n",
       "      <td>nl -s - -b a -n __SP__UNK</td>\n",
       "      <td>'</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nl -s __SP__UNK - | nl</td>\n",
       "      <td>'</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nl -s - __SP__UNK | nl -n __SP__UNK</td>\n",
       "      <td>'</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nl -s __SP__UNK - | nl -n __SP__UNK</td>\n",
       "      <td>'</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b'</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nl -s - __SP__UNK | nl -s - __SP__UNK | nl -n ...</td>\n",
       "      <td>'</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  example_id                                        description  \\\n",
       "0        b'0  Adds execution permissions on a script ./etc/b...   \n",
       "1         b'                                                NaN   \n",
       "2         b'                                                NaN   \n",
       "3         b'                                                NaN   \n",
       "4         b'                                                NaN   \n",
       "5        b'1  Add prefix like number and \"^M${LOGFILE}> \" to...   \n",
       "6         b'                                                NaN   \n",
       "7         b'                                                NaN   \n",
       "8         b'                                                NaN   \n",
       "9         b'                                                NaN   \n",
       "\n",
       "                                    ground_truth  \\\n",
       "0  chmod +x $(brew --prefix)/etc/bash_completion   \n",
       "1                                            NaN   \n",
       "2                                            NaN   \n",
       "3                                            NaN   \n",
       "4                                            NaN   \n",
       "5                         nl -s\"^M${LOGFILE}>  \"   \n",
       "6                                            NaN   \n",
       "7                                            NaN   \n",
       "8                                            NaN   \n",
       "9                                            NaN   \n",
       "\n",
       "                                          prediction  correct template  \\\n",
       "0                                                NaN                 '   \n",
       "1       find __SP__UNK -type d -exec chmod +x {} \\\\;                 '   \n",
       "2  find __SP__UNK -type d -exec chmod __SP__UNK {...                 '   \n",
       "3  find __SP__UNK -type d -print0 | xargs -0 -I {...                 '   \n",
       "4       find __SP__UNK -type f -exec chmod +x {} \\\\;                 '   \n",
       "5                          nl -s - -b a -n __SP__UNK                 '   \n",
       "6                             nl -s __SP__UNK - | nl                 '   \n",
       "7                nl -s - __SP__UNK | nl -n __SP__UNK                 '   \n",
       "8                nl -s __SP__UNK - | nl -n __SP__UNK                 '   \n",
       "9  nl -s - __SP__UNK | nl -s - __SP__UNK | nl -n ...                 '   \n",
       "\n",
       "   correct command  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  \n",
       "5              NaN  \n",
       "6              NaN  \n",
       "7              NaN  \n",
       "8              NaN  \n",
       "9              NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head(10) # correct template, correct command are meaningless.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = []\n",
    "\n",
    "for idx, row in result_df.iterrows():\n",
    "    data_index = row.example_id[2:]\n",
    "    if len(data_index) != 0:\n",
    "        eval_data.append(\n",
    "            metric_utils.EvalDataPoint(int(data_index))\n",
    "        )\n",
    "    \n",
    "    if row[' description'] == row[' description']: # nan detection\n",
    "        eval_data[-1].description = row[' description']\n",
    "    \n",
    "    if row[' ground_truth'] == row[' ground_truth']:\n",
    "        eval_data[-1].gt_data.append(row[' ground_truth'])\n",
    "    \n",
    "    if row[' prediction'] == row[' prediction']:\n",
    "        eval_data[-1].pred_data.append(row[' prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions from src/evaluate.py\n",
    "def get_score(prediction_scores):\n",
    "    score = -1.0\n",
    "    if len(prediction_scores) == 0:\n",
    "        return score\n",
    "\n",
    "    has_positive_score = True in [x > 0 for x in prediction_scores]\n",
    "\n",
    "    if has_positive_score:\n",
    "        score = max(prediction_scores)\n",
    "    else:\n",
    "        score = sum(prediction_scores) / float(len(prediction_scores))\n",
    "\n",
    "    return score\n",
    "\n",
    "def compute_score(ground_truths, predicted_cmds, predicted_confds, metric_params, verbose=False):\n",
    "    \n",
    "    prediction_scores = []\n",
    "\n",
    "    for grnd_truth_cmd in ground_truths:\n",
    "        for i, predicted_cmd in enumerate(predicted_cmds):\n",
    "            \n",
    "            if predicted_cmd is None or len(predicted_cmd) == 0:\n",
    "                continue\n",
    "            \n",
    "            predicted_confidence = predicted_confds[i]\n",
    "            pair_score = metric_utils.compute_metric(predicted_cmd, predicted_confidence, grnd_truth_cmd, metric_params)\n",
    "            prediction_scores.append(pair_score)\n",
    "\n",
    "    score = get_score(prediction_scores)\n",
    "\n",
    "    if verbose:\n",
    "        print('-' * 50)\n",
    "        print(f'Ground truth: {ground_truths}')\n",
    "        print(f'Predictions: {predicted_cmds}')\n",
    "        print(f'Prediction scores: {prediction_scores}')\n",
    "        print(f'Score: {score}')\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Ground truth: ['chmod +x $(brew --prefix)/etc/bash_completion']\n",
      "Predictions: ['find __SP__UNK -type d -exec chmod +x {} \\\\\\\\;', 'find __SP__UNK -type d -exec chmod __SP__UNK {} \\\\\\\\;', 'find __SP__UNK -type d -print0 | xargs -0 -I {} chmod +x {}', 'find __SP__UNK -type f -exec chmod +x {} \\\\\\\\;']\n",
      "Score: -1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single datapoint showcase\n",
    "params = {\n",
    "  \"u1\": 1.0,\n",
    "  \"u2\": 1.0\n",
    "}\n",
    "\n",
    "def dp2score(dp, params=params, verbose=False):\n",
    "    # justa a quality-of-life function\n",
    "    return compute_score(dp.gt_data, dp.pred_data, [1]*len(dp.pred_data), params, verbose=verbose)\n",
    "\n",
    "dp2score(eval_data[0], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Ground truth: ['rsync -rvz --chmod=ugo=rwX -e ssh source destination']\n",
      "Predictions: ['rsync -rvz --chmod=ugo=rwX -e ssh source destination']\n",
      "Prediction scores: [0.0]\n",
      "Score: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ok, so... we should probably filter out cases where gt marked on gt doesn't get perfect score.\n",
    "\n",
    "# Example:\n",
    "dp = eval_data[8]\n",
    "compute_score(dp.gt_data, dp.gt_data, [1]*len(dp.pred_data), params, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtered: 701\n",
      "After filtered: 505\n"
     ]
    }
   ],
   "source": [
    "# Filtering:\n",
    "filter_func = lambda dp: compute_score(dp.gt_data, dp.gt_data, [1]*len(dp.gt_data), params) != 0.\n",
    "filtered_data = list(filter(filter_func, eval_data))\n",
    "print('Before filtered:', len(eval_data))\n",
    "print('After filtered:', len(filtered_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating scores takes some time actually\n",
    "all_scores = list(map(dp2score, filtered_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering by score showcase\n",
    "threshold = 0.0\n",
    "with open(f'BadCases_{threshold}.txt', 'w') as f:\n",
    "    for score, dp in zip(all_scores, filtered_data):\n",
    "        if score < threshold:\n",
    "            print(f'----- ID: {dp.index} -----', file=f)\n",
    "            print(f'GT(s):', file=f)\n",
    "            print('\\n'.join(dp.gt_data), file=f)\n",
    "            print(f'Predictions:', file=f)\n",
    "            print('\\n'.join(dp.pred_data), file=f)\n",
    "            print(f'Score: {score}', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 505\n",
      "Average: 0.2654118117764157\n",
      "Median: 0.5\n",
      "Number of perfect scores: 187\n",
      "Number of completely wrong: 59\n",
      "Positive scores: 332\n",
      "Sub-zero scores: 166\n",
      "Number of balanced: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# score distribution showcase\n",
    "\n",
    "n_by_bin, _, _ = plt.hist(all_scores)\n",
    "\n",
    "print('Total:', len(all_scores))\n",
    "print('Average:', np.mean(all_scores))\n",
    "print('Median:', np.median(all_scores))\n",
    "print('Number of perfect scores:', len([e for e in all_scores if 1-e<1e-4]))\n",
    "print('Number of completely wrong:', len([e for e in all_scores if e+1<1e-4]))\n",
    "print('Positive scores:', len([e for e in all_scores if e > 0]))\n",
    "print('Sub-zero scores:', len([e for e in all_scores if e < 0]))\n",
    "print('Number of balanced:', len([e for e in all_scores if abs(e)<1e-4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([239.,  39.,  45.,  22.,   4.,  35.,  32.,  54.,  37., 194.]),\n",
       " array([-1. , -0.8, -0.6, -0.4, -0.2,  0. ,  0.2,  0.4,  0.6,  0.8,  1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_by_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT()\n",
      "    UTILITY(comm)\n",
      "        FLAG(-2)\n",
      "        FLAG(-3)\n",
      "        PROCESSSUBSTITUTION(<)\n",
      "            UTILITY(ls)\n",
      "        PROCESSSUBSTITUTION(<)\n",
      "            UTILITY(ls)\n",
      "                ARGUMENT(*Music*)<File>\n"
     ]
    }
   ],
   "source": [
    "ast = bashlint.data_tools.bash_parser('comm -23 <(ls) <(ls *Music*)')\n",
    "bashlint.data_tools.pretty_print(ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Ground truth: ['sudo chown root:root testfile.txt']\n",
      "Predictions: ['chown root:root __SP__UNK']\n",
      "Prediction scores: [1.0]\n",
      "Score: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score(['sudo chown root:root testfile.txt'], ['chown root:root __SP__UNK'], [1], params, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clai-env",
   "language": "python",
   "name": "clai-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
